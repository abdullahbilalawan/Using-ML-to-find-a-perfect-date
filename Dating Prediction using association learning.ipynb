{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv('speed-dating_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6</td>\n",
       "      <td>[4-6]</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>latino/hispanic american</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  wave  gender   age  age_o  d_age d_d_age  \\\n",
       "0         0     1  female  21.0   27.0      6   [4-6]   \n",
       "1         0     1  female  21.0   22.0      1   [0-1]   \n",
       "2         1     1  female  21.0   22.0      1   [0-1]   \n",
       "3         0     1  female  21.0   23.0      2   [2-3]   \n",
       "4         0     1  female  21.0   24.0      3   [2-3]   \n",
       "\n",
       "                                    race  \\\n",
       "0  asian/pacific islander/asian-american   \n",
       "1  asian/pacific islander/asian-american   \n",
       "2  asian/pacific islander/asian-american   \n",
       "3  asian/pacific islander/asian-american   \n",
       "4  asian/pacific islander/asian-american   \n",
       "\n",
       "                                  race_o  samerace  ...  \\\n",
       "0            european/caucasian-american         0  ...   \n",
       "1            european/caucasian-american         0  ...   \n",
       "2  asian/pacific islander/asian-american         1  ...   \n",
       "3            european/caucasian-american         0  ...   \n",
       "4               latino/hispanic american         0  ...   \n",
       "\n",
       "   d_expected_num_interested_in_me  d_expected_num_matches like  \\\n",
       "0                            [0-3]                   [3-5]  7.0   \n",
       "1                            [0-3]                   [3-5]  7.0   \n",
       "2                            [0-3]                   [3-5]  7.0   \n",
       "3                            [0-3]                   [3-5]  7.0   \n",
       "4                            [0-3]                   [3-5]  6.0   \n",
       "\n",
       "  guess_prob_liked d_like  d_guess_prob_liked  met  decision  decision_o  \\\n",
       "0              6.0  [6-8]               [5-6]  0.0         1           0   \n",
       "1              5.0  [6-8]               [5-6]  1.0         1           0   \n",
       "2              NaN  [6-8]               [0-4]  1.0         1           1   \n",
       "3              6.0  [6-8]               [5-6]  0.0         1           1   \n",
       "4              6.0  [6-8]               [5-6]  0.0         1           1   \n",
       "\n",
       "   match  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_null\n",
      "wave\n",
      "gender\n",
      "age\n",
      "age_o\n",
      "d_age\n",
      "d_d_age\n",
      "race\n",
      "race_o\n",
      "samerace\n",
      "importance_same_race\n",
      "importance_same_religion\n",
      "d_importance_same_race\n",
      "d_importance_same_religion\n",
      "field\n",
      "pref_o_attractive\n",
      "pref_o_sincere\n",
      "pref_o_intelligence\n",
      "pref_o_funny\n",
      "pref_o_ambitious\n",
      "pref_o_shared_interests\n",
      "d_pref_o_attractive\n",
      "d_pref_o_sincere\n",
      "d_pref_o_intelligence\n",
      "d_pref_o_funny\n",
      "d_pref_o_ambitious\n",
      "d_pref_o_shared_interests\n",
      "attractive_o\n",
      "sinsere_o\n",
      "intelligence_o\n",
      "funny_o\n",
      "ambitous_o\n",
      "shared_interests_o\n",
      "d_attractive_o\n",
      "d_sinsere_o\n",
      "d_intelligence_o\n",
      "d_funny_o\n",
      "d_ambitous_o\n",
      "d_shared_interests_o\n",
      "attractive_important\n",
      "sincere_important\n",
      "intellicence_important\n",
      "funny_important\n",
      "ambtition_important\n",
      "shared_interests_important\n",
      "d_attractive_important\n",
      "d_sincere_important\n",
      "d_intellicence_important\n",
      "d_funny_important\n",
      "d_ambtition_important\n",
      "d_shared_interests_important\n",
      "attractive\n",
      "sincere\n",
      "intelligence\n",
      "funny\n",
      "ambition\n",
      "d_attractive\n",
      "d_sincere\n",
      "d_intelligence\n",
      "d_funny\n",
      "d_ambition\n",
      "attractive_partner\n",
      "sincere_partner\n",
      "intelligence_partner\n",
      "funny_partner\n",
      "ambition_partner\n",
      "shared_interests_partner\n",
      "d_attractive_partner\n",
      "d_sincere_partner\n",
      "d_intelligence_partner\n",
      "d_funny_partner\n",
      "d_ambition_partner\n",
      "d_shared_interests_partner\n",
      "sports\n",
      "tvsports\n",
      "exercise\n",
      "dining\n",
      "museums\n",
      "art\n",
      "hiking\n",
      "gaming\n",
      "clubbing\n",
      "reading\n",
      "tv\n",
      "theater\n",
      "movies\n",
      "concerts\n",
      "music\n",
      "shopping\n",
      "yoga\n",
      "d_sports\n",
      "d_tvsports\n",
      "d_exercise\n",
      "d_dining\n",
      "d_museums\n",
      "d_art\n",
      "d_hiking\n",
      "d_gaming\n",
      "d_clubbing\n",
      "d_reading\n",
      "d_tv\n",
      "d_theater\n",
      "d_movies\n",
      "d_concerts\n",
      "d_music\n",
      "d_shopping\n",
      "d_yoga\n",
      "interests_correlate\n",
      "d_interests_correlate\n",
      "expected_happy_with_sd_people\n",
      "expected_num_interested_in_me\n",
      "expected_num_matches\n",
      "d_expected_happy_with_sd_people\n",
      "d_expected_num_interested_in_me\n",
      "d_expected_num_matches\n",
      "like\n",
      "guess_prob_liked\n",
      "d_like\n",
      "d_guess_prob_liked\n",
      "met\n",
      "decision\n",
      "decision_o\n",
      "match\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        WWMMKLNNDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using association rule learning on the basis of race of opposite genders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Race_data= dataset[['race','race_o']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "      <td>latino/hispanic american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8373</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>latino/hispanic american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8374</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8375</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>latino/hispanic american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8376</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8377</td>\n",
       "      <td>european/caucasian-american</td>\n",
       "      <td>asian/pacific islander/asian-american</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8378 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       race  \\\n",
       "0     asian/pacific islander/asian-american   \n",
       "1     asian/pacific islander/asian-american   \n",
       "2     asian/pacific islander/asian-american   \n",
       "3     asian/pacific islander/asian-american   \n",
       "4     asian/pacific islander/asian-american   \n",
       "...                                     ...   \n",
       "8373            european/caucasian-american   \n",
       "8374            european/caucasian-american   \n",
       "8375            european/caucasian-american   \n",
       "8376            european/caucasian-american   \n",
       "8377            european/caucasian-american   \n",
       "\n",
       "                                     race_o  \n",
       "0               european/caucasian-american  \n",
       "1               european/caucasian-american  \n",
       "2     asian/pacific islander/asian-american  \n",
       "3               european/caucasian-american  \n",
       "4                  latino/hispanic american  \n",
       "...                                     ...  \n",
       "8373               latino/hispanic american  \n",
       "8374                                  other  \n",
       "8375               latino/hispanic american  \n",
       "8376  asian/pacific islander/asian-american  \n",
       "8377  asian/pacific islander/asian-american  \n",
       "\n",
       "[8378 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Race_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lists=[]\n",
    "for i in range (0,8378):\n",
    "    lists.append([str(Race_data.values[i,j])for j in range(0,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asian/pacific islander/asian-american', 'european/caucasian-american']\n",
      "['asian/pacific islander/asian-american', 'european/caucasian-american']\n",
      "['asian/pacific islander/asian-american', 'asian/pacific islander/asian-american']\n",
      "['asian/pacific islander/asian-american', 'european/caucasian-american']\n",
      "['asian/pacific islander/asian-american', 'latino/hispanic american']\n",
      "['asian/pacific islander/asian-american', 'european/caucasian-american']\n",
      "['asian/pacific islander/asian-american', 'european/caucasian-american']\n",
      "['asian/pacific islander/asian-american', 'european/caucasian-american']\n",
      "['asian/pacific islander/asian-american', 'european/caucasian-american']\n",
      "['asian/pacific islander/asian-american', 'european/caucasian-american']\n"
     ]
    }
   ],
   "source": [
    "counter =0\n",
    "\n",
    "for i in lists:\n",
    "    print(i)\n",
    "    counter+=1\n",
    "    if counter ==10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have  a list of lists with required race and partner race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.095488183337312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimating minimum support for the race used at least 80 times in 10 days\n",
    "minimumsupport= (80*10)/8378\n",
    "minimumsupport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = apriori(lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RelationRecord(items=frozenset({'asian/pacific islander/asian-american'}), support=0.41537359751730724, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'asian/pacific islander/asian-american'}), confidence=0.41537359751730724, lift=1.0)]),\n",
       " RelationRecord(items=frozenset({'european/caucasian-american'}), support=0.802697541179279, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'european/caucasian-american'}), confidence=0.802697541179279, lift=1.0)]),\n",
       " RelationRecord(items=frozenset({'latino/hispanic american'}), support=0.15230365242301266, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'latino/hispanic american'}), confidence=0.15230365242301266, lift=1.0)]),\n",
       " RelationRecord(items=frozenset({'other'}), support=0.11947958940081164, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'other'}), confidence=0.11947958940081164, lift=1.0)]),\n",
       " RelationRecord(items=frozenset({'european/caucasian-american', 'asian/pacific islander/asian-american'}), support=0.2604440200525185, ordered_statistics=[OrderedStatistic(items_base=frozenset({'asian/pacific islander/asian-american'}), items_add=frozenset({'european/caucasian-american'}), confidence=0.6270114942528735, lift=0.7811304533606802), OrderedStatistic(items_base=frozenset({'european/caucasian-american'}), items_add=frozenset({'asian/pacific islander/asian-american'}), confidence=0.3244609665427509, lift=0.7811304533606802)])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = list(rules)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule: asian/pacific islander/asian-american      race from a -> b \n",
      "Support: 0.41537359751730724\n",
      "Confidence: 0.41537359751730724\n",
      "Lift: 1.0\n",
      "=====================================\n",
      "Rule: european/caucasian-american      race from a -> b \n",
      "Support: 0.802697541179279\n",
      "Confidence: 0.802697541179279\n",
      "Lift: 1.0\n",
      "=====================================\n",
      "Rule: latino/hispanic american      race from a -> b \n",
      "Support: 0.15230365242301266\n",
      "Confidence: 0.15230365242301266\n",
      "Lift: 1.0\n",
      "=====================================\n",
      "Rule: other      race from a -> b \n",
      "Support: 0.11947958940081164\n",
      "Confidence: 0.11947958940081164\n",
      "Lift: 1.0\n",
      "=====================================\n",
      "Rule: european/caucasian-american      race from a -> b \n",
      "Support: 0.2604440200525185\n",
      "Confidence: 0.6270114942528735\n",
      "Lift: 0.7811304533606802\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "for item in results:\n",
    "\n",
    "    # first index of the inner list\n",
    "    # Contains base item and add item\n",
    "    pair = item[0] \n",
    "    items = [x for x in pair]\n",
    "    print(\"Rule: \" + items[0] + \"     \"+\" race from a -> b \" )\n",
    "\n",
    "    #second index of the inner list\n",
    "    print(\"Support: \" + str(item[1]))\n",
    "\n",
    "    #third index of the list located at 0th\n",
    "    #of the third index of the inner list\n",
    "\n",
    "    print(\"Confidence: \" + str(item[2][0][2]))\n",
    "    print(\"Lift: \" + str(item[2][0][3]))\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose your natural race:\n",
      "\n",
      "\n",
      "1.asian/pacific\n",
      "2.islander/asian-american\n",
      "3.european\n",
      "4.hispanic american\n",
      "5.caucasian-american \n",
      "6.latino\n",
      "\n",
      "\n",
      "Your race number:2\n"
     ]
    }
   ],
   "source": [
    "print ('Choose your natural race:')\n",
    "\n",
    "print('''\n",
    "\n",
    "1.asian/pacific\n",
    "2.islander/asian-american\n",
    "3.european\n",
    "4.hispanic american\n",
    "5.caucasian-american \n",
    "6.latino\n",
    "\n",
    "''')\n",
    "\n",
    "\n",
    "x= input('Your race number:')\n",
    "\n",
    "if x ==1:\n",
    "    print('you should enjoy date with a islander/asian-american')\n",
    "    \n",
    "if x==2:\n",
    "    print('you should enjoy date with a asian')\n",
    "if x==3:\n",
    "    print('you should enjoy date with  a caucasian-american')\n",
    "    \n",
    "if x==4:\n",
    "    print('you should enjoy date with a latino')\n",
    "    \n",
    "if x==5:\n",
    "    print('you should enjoy date with a eurpeon')\n",
    "    \n",
    "if x==6:\n",
    "    print('you should enjoy date with  a islander')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if x ==1:\n",
    "    print('you should enjoy date with a islander/asian-american')\n",
    "    \n",
    "if x==2:\n",
    "    print('you should enjoy date with a asian')\n",
    "if x==3:\n",
    "    print('you should enjoy date with  a caucasian-american')\n",
    "    \n",
    "if x==4:\n",
    "    print('you should enjoy date with a latino')\n",
    "    \n",
    "if x==5:\n",
    "    print('you should enjoy date with a eurpeon')\n",
    "    \n",
    "if x==6:\n",
    "    print('you should enjoy date with  a islander')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
